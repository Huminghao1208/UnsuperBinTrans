{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, json, os, pickle, re, time\n",
    "from os.path import expanduser\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_filename_too_long(long_name):\n",
    "    long_name = long_name.split(\".gdl\")[0:]\n",
    "    long_name = long_name[0]\n",
    "    before_at_1 = long_name.split(\"@\")[0]\n",
    "    after_at_1 = long_name.split(\"@\")[1]\n",
    "    new_name = before_at_1 + \"@\" + after_at_1[:30] + after_at_1[-30:] + '_funcGNN_formatted.txt'\n",
    "\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(string):\n",
    "    result = [e for e in re.split(\"[^0-9]\", string) if e != '']\n",
    "\n",
    "    # list 'result' elements are strings: ['3', '17', '14'], so we use map(int, list) to get integers\n",
    "    return max(map(int, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the line with ~\n",
    "def write_line(line):\n",
    "    out_line = ''\n",
    "    for i, token in enumerate(line):\n",
    "        if i > 0 and out_line[-1] != ',':\n",
    "            out_line += '~'\n",
    "        out_line += token.upper()\n",
    "    return out_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_segment_reg_offset_len(temp):\n",
    "    if temp.strip().endswith(']'):\n",
    "        if len(temp.strip()) <= 12:\n",
    "            return True\n",
    "\n",
    "    if temp.strip().endswith('h') or temp.strip().endswith('H'):\n",
    "        if not len(temp.strip()) > 5:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace labels and tags\n",
    "def replace_labels(arch, line, function_names):\n",
    "    if arch == 'x86':\n",
    "        # call + function_name\n",
    "        if line[0] == 'call':\n",
    "            pass\n",
    "\n",
    "        # replace function names with <FOO>\n",
    "        if not line[0].startswith('call'):\n",
    "            for i, token in enumerate(line):\n",
    "                if token == '=':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line.remove(token)\n",
    "                    continue\n",
    "\n",
    "                # replace string data type\n",
    "                if token.startswith('_STR_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = '<STRING>'\n",
    "                    continue\n",
    "\n",
    "                # replace function names in the air\n",
    "                if token.startswith('__') or token.startswith('_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                # replace arg_abc types\n",
    "                if token.startswith('arg_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = '<ARG>'\n",
    "                    continue\n",
    "\n",
    "                # replace var_abc types\n",
    "                if token.startswith('var_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = '<VAR>'\n",
    "                    continue\n",
    "\n",
    "                # replace offset\n",
    "                if token == 'offset':\n",
    "                    line[i] = 'OFFSET'\n",
    "                    continue\n",
    "\n",
    "                if token == 'short':\n",
    "                    line[i] = 'SHORT'\n",
    "                    continue\n",
    "\n",
    "                if token == 'jmp':\n",
    "                    line[i] = 'JMP'\n",
    "                    continue\n",
    "\n",
    "                if token == 'leave':\n",
    "                    line[i] = 'LEAVE'\n",
    "                    continue\n",
    "\n",
    "                if token == 'proc':\n",
    "                    return None\n",
    "\n",
    "                if token == 'near':\n",
    "                    return None\n",
    "\n",
    "                if token == 'endp':\n",
    "                    return None\n",
    "\n",
    "                if i != 0 and (re.sub('\\A[0-9A-Fa-f.-]+\\Z', '0', token) == '0' or re.sub('[0-9A-Fa-f.-]+h', '0',\n",
    "                                                                                         token) == '0'):\n",
    "                    if len(line[i].strip()) > 5:\n",
    "                        line[i] = '<CONST>'\n",
    "                    continue\n",
    "\n",
    "                # replace segment registers\n",
    "                # \"segment register : offset register\"; A segment register is one of CS, DS, ES, FS, GS, or SS)\n",
    "                if token.startswith('cs:'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'cs:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('ds:'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'ds:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('es:'):\n",
    "                    print('token.startswith(es:) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "\n",
    "\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'es:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('fs:'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'fs:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('gs:'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'gs:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('ss:'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    temp = token[3:]\n",
    "\n",
    "                    if check_segment_reg_offset_len(temp):\n",
    "                        if token[-1] == ',':\n",
    "                            line[i] += ','\n",
    "                        continue\n",
    "\n",
    "                    if temp.startswith('dword_'):\n",
    "                        temp = 'dword_<ADDR>'\n",
    "                    elif temp.startswith('qword_'):\n",
    "                        temp = 'qword_<ADDR>'\n",
    "                    else:\n",
    "                        temp = '<ADDR>'\n",
    "                    line[i] = 'ss:' + temp\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                # replace data types\n",
    "                if token == '<XMMWORD_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token == '<DWORD_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token == '<QWORD_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token == '<TBYTE_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token == '<BYTE_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token == '<WORD_PTR>':\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                # replace dummy name prefixes from ida\n",
    "                # this has to be the last step of the whole filtering process\n",
    "                # refer to https://hex-rays.com/blog/igors-tip-of-the-week-34-dummy-names/\n",
    "                if token.startswith('sub_'):\n",
    "                    print('req_token_sub_ = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('def_'):\n",
    "                    print('token.startswith(def_) = ', token)\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'DEF_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('locret_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'locret_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('loc_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "\n",
    "                    line[i] = 'loc_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('off_'):\n",
    "                    print('token.startswith(off_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'off_<OFFSET>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('seg_'):\n",
    "                    print('token.startswith(seg_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'seg_<ADDR>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('asc_'):\n",
    "                    print('token.startswith(asc_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'asc_<STR>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('byte_'):\n",
    "                    print('token.startswith(byte_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'byte_<BYTE>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('word_'):\n",
    "                    print('token.startswith(word_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'word_<WORD>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('dword_'):\n",
    "                    print('token.startswith(dword_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'DWORD_<WORD>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('qword_'):\n",
    "                    print('token.startswith(qword_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'qword_<WORD>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('byte3_'):\n",
    "                    print('token.startswith(byte3_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'byte3_<BYTE>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('xmmword_'):\n",
    "                    print('token.startswith(xmmword_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'xmmword_<WORD>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('ymmword_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'ymmword_<WORD>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('packreal_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'packreal_<BIT>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('flt_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'flt_<BIT>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('dbl_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'dbl_<BIT>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('tbyte_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'tbyte_<BYTE>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('stru_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'stru_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('custdata_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'custdata_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('algn_'):\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'algn_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                if token.startswith('unk_'):\n",
    "                    print('token.startswith(unk_) = ', token)\n",
    "\n",
    "                    if i == 0:\n",
    "                        return None\n",
    "                    line[i] = 'unk_<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                # starting with opcode\n",
    "                if i == 0:\n",
    "                    continue\n",
    "\n",
    "                if token in x86_regi_set:\n",
    "                    continue\n",
    "\n",
    "                if token in x86_reg_re:\n",
    "                    continue\n",
    "\n",
    "                # random missed opcodes\n",
    "                if token in missed_opcodes:\n",
    "                    continue\n",
    "\n",
    "                # [rax + 8]\n",
    "                if token[0] == '[':\n",
    "                    if token[-1] == ',':\n",
    "                        comma = True\n",
    "                        token = token[:-1]\n",
    "                    else:\n",
    "                        comma = False\n",
    "                    # remove the '[]'\n",
    "                    temp = token[1: -1]\n",
    "\n",
    "                    # mark the punctuation\n",
    "                    symbol = '+'\n",
    "                    if '-' in temp:\n",
    "                        symbol = '-'\n",
    "\n",
    "                    # split by symbol\n",
    "                    items = temp.split(symbol)\n",
    "                    for idx, item in enumerate(items):\n",
    "                        # search for asterisk *\n",
    "                        if '*' in item:\n",
    "                            sub_items = item.split('*')\n",
    "\n",
    "                            for idx_s, s in enumerate(sub_items):\n",
    "                                sub_items[idx_s] = token_helper(s, function_names)\n",
    "\n",
    "                            items[idx] = '*'.join(sub_items)\n",
    "                            continue\n",
    "\n",
    "                        items[idx] = token_helper(item, function_names)\n",
    "\n",
    "                    line[i] = '[' + symbol.join(items) + ']'\n",
    "                    if comma:\n",
    "                        line[i] += ','\n",
    "                    continue\n",
    "\n",
    "                # NO MATCH. Shouldn't be there\n",
    "                else:\n",
    "                    line[i] = '<TAG>'\n",
    "                    if token[-1] == ',':\n",
    "                        line[i] += ','\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_helper(token, function_names):\n",
    "    if token.startswith('var_'):\n",
    "        return '<VAR>'\n",
    "\n",
    "    if token.startswith('arg_'):\n",
    "        return '<ARG>'\n",
    "\n",
    "    if re.sub('\\A[0-9A-Fa-f.-]+\\Z', '0', token) == '0' or re.sub('[0-9A-Fa-f.-]+h', '0', token) == '0':\n",
    "        if len(token.strip()) > 5:\n",
    "            return '<CONST>'\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(instruction_list, file_path):\n",
    "    with open(file_path, 'w') as fp_out:\n",
    "        for inst in instruction_list:\n",
    "            fp_out.write(inst + '\\n')\n",
    "    fp_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gdl_processing(input_file, output_file, output_file_gdl):\n",
    "    with open(input_file, 'r') as fp_in, open(output_file, 'w') as fp_out, open(output_file_gdl, 'w') as fp_out_gdl:\n",
    "        print('input_file = ', input_file)\n",
    "        lines = fp_in.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            ori = line\n",
    "\n",
    "            if i > 10:\n",
    "                last_line = lines[-1]\n",
    "                if line != last_line:\n",
    "                    next_line = lines[i + 1]\n",
    "                    if line.startswith('node:') and next_line.startswith('// node 0'):\n",
    "                        fp_out.write('\\n0')\n",
    "                        fp_out_gdl.write('\\n0')\n",
    "\n",
    "                        continue\n",
    "                    if line.startswith('node:') and next_line.startswith('node:'):\n",
    "                        fp_out.write('\\n0')\n",
    "                        fp_out_gdl.write('\\n0')\n",
    "\n",
    "                        continue\n",
    "                    if line.startswith('// node 0'):\n",
    "                        fp_out.write('\\n')\n",
    "                        fp_out_gdl.write('}\\n')\n",
    "                        continue\n",
    "\n",
    "                if line.startswith('colorentry'):\n",
    "                    continue\n",
    "                if line.startswith('endbr64'):\n",
    "                    continue\n",
    "                if line.startswith('}'):\n",
    "                    continue\n",
    "                if line.startswith('node'):\n",
    "                    fp_out.write('\\n')\n",
    "                    if 'title: \"0\"' in line:\n",
    "                        fp_out_gdl.write(line.replace(\"\\n\", \"\") + ' @BB\\n')\n",
    "                    else:\n",
    "                        fp_out_gdl.write(\"}\\n\" + line.replace(\"\\n\", \"\") + ' @BB\\n')\n",
    "\n",
    "                    continue\n",
    "                elif line.startswith('edge'):\n",
    "                    fp_out_gdl.write(line)\n",
    "                    line = line.replace('\"', '')\n",
    "                    res = [int(number) for number in line.split() if number.isdigit()]\n",
    "                    fp_out.write(str(res) + \" \")\n",
    "                    continue\n",
    "                elif line.startswith('// node 0'):\n",
    "                    fp_out.write(\"\\n\")\n",
    "                    fp_out_gdl.write(\"\\n\")\n",
    "\n",
    "                    continue\n",
    "                elif line.startswith('// node'):\n",
    "                    continue\n",
    "                if '\"' in line:\n",
    "                    line = line.split('\"')\n",
    "                    line = line[0]\n",
    "                if ';' in line:\n",
    "                    line = line.split(';')\n",
    "                    line = line[0]\n",
    "\n",
    "                if 'xmmword ptr' in line:\n",
    "                    line = line.replace('xmmword ptr', '<XMMWORD_PTR>')\n",
    "                if 'qword ptr' in line:\n",
    "                    line = line.replace('qword ptr', '<QWORD_PTR>')\n",
    "                if 'dword ptr' in line:\n",
    "                    line = line.replace('dword ptr', '<DWORD_PTR>')\n",
    "                if 'tbyte ptr' in line:\n",
    "                    line = line.replace('tbyte ptr', '<TBYTE_PTR>')\n",
    "                if 'byte ptr' in line:\n",
    "                    line = line.replace('byte ptr', '<BYTE_PTR>')\n",
    "                if 'word ptr' in line:\n",
    "                    line = line.replace('word ptr', '<WORD_PTR>')\n",
    "\n",
    "                line = line.split()\n",
    "                if line[0] == 'endbr64':\n",
    "                    continue\n",
    "\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if 'retn' in line[0]:\n",
    "                    line = ['retn']\n",
    "\n",
    "                line = replace_labels(architecture, line, function_names)\n",
    "                line = write_line(line)\n",
    "                fp_out.write(line + ' ')\n",
    "                fp_out_gdl.write(line + '\\n')\n",
    "                unique_instructions.add(line)\n",
    "                instruction_mapping[line].add(ori)\n",
    "\n",
    "        fp_in.close()\n",
    "        fp_out.close()\n",
    "        fp_out_gdl.close()\n",
    "\n",
    "        with open(output_file, \"r\") as inp:\n",
    "            lines = inp.readlines()\n",
    "            if lines[0] == '\\n':\n",
    "                lines = lines[1:]\n",
    "            count = len(lines)\n",
    "            # count = len(open(output_file).readlines())\n",
    "            new_file_lines = []\n",
    "            current_line = [None] * count\n",
    "            for i, line in enumerate(lines):\n",
    "                current_line[i] = line.strip()\n",
    "            if len(current_line) > 2 and not re.search('[a-zA-Z]', current_line[-1]):\n",
    "                new_file_lines.append(current_line[:len(current_line) - 1])\n",
    "                new_file_lines[0] = list(filter(None, new_file_lines[0]))\n",
    "                new_file_lines.append(current_line[len(current_line) - 1:])\n",
    "            else:\n",
    "                new_file_lines.append(current_line)\n",
    "                new_file_lines[0] = list(filter(None, new_file_lines[0]))\n",
    "\n",
    "        with open(output_file, \"w\") as outfile:\n",
    "\n",
    "            if len(new_file_lines) > 1:\n",
    "                for line in new_file_lines[:-1]:\n",
    "                    outfile.write(\"labels_ \")\n",
    "                    jd = json.dumps(line)\n",
    "                    print(jd, end=\"\\n\", file=outfile)\n",
    "                for line in new_file_lines[1:]:\n",
    "                    line = str(line)\n",
    "                    line = re.sub(r\"\\]\\s\", \"], \", line)\n",
    "                    line = ast.literal_eval(line)\n",
    "                    outfile.write(\"graph_ [\" + line[0] + \"]\")\n",
    "            else:\n",
    "                for line in new_file_lines:\n",
    "                    outfile.write(\"labels_ \")\n",
    "                    jd = json.dumps(line)\n",
    "                    print(jd, end=\"\\n\", file=outfile)\n",
    "                    outfile.write(\"graph_ [[0, 0]]\")\n",
    "\n",
    "        with open((output_file), 'r') as input:\n",
    "            lines = input.readlines()\n",
    "            labels = lines[0].split(\"_ \")\n",
    "            labels = ast.literal_eval(labels[1])\n",
    "            graph_length = len(labels) - 1\n",
    "            graph = lines[1].split(\"_ \")\n",
    "            graph = graph[1]\n",
    "            graph_max = find_max(graph)\n",
    "\n",
    "            while graph_max > graph_length:\n",
    "                labels.append('0')\n",
    "                graph_length = len(labels) - 1\n",
    "\n",
    "            with open(output_file, \"w\") as outfile:\n",
    "                outfile.write(\"labels_ \")\n",
    "                jd = json.dumps(labels)\n",
    "                print(jd, end=\"\\n\", file=outfile)\n",
    "                outfile.write(\"graph_ \" + str(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes the main function\n",
    "def preprocessing(input_file, output_file):\n",
    "    with open(input_file, 'r') as fp_in, open(output_file, 'w') as fp_out:\n",
    "        lines = fp_in.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            ori = line\n",
    "            if 'xmmword ptr' in line:\n",
    "                line = line.replace('xmmword ptr', '<XMMWORD_PTR>')\n",
    "            if 'qword ptr' in line:\n",
    "                line = line.replace('qword ptr', '<QWORD_PTR>')\n",
    "            if 'dword ptr' in line:\n",
    "                line = line.replace('dword ptr', '<DWORD_PTR>')\n",
    "            if 'tbyte ptr' in line:\n",
    "                line = line.replace('tbyte ptr', '<TBYTE_PTR>')\n",
    "            if 'byte ptr' in line:\n",
    "                line = line.replace('byte ptr', '<BYTE_PTR>')\n",
    "            if 'word ptr' in line:\n",
    "                line = line.replace('word ptr', '<WORD_PTR>')\n",
    "\n",
    "            line = line.split()\n",
    "            if line[0] == 'endbr64' or line[0] == 'dq':\n",
    "                continue\n",
    "            line = replace_labels(architecture, line, function_names)\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            line = write_line(line)\n",
    "            fp_out.write(line + '\\n')\n",
    "        fp_in.close()\n",
    "        fp_out.close()  \n",
    "\n",
    "# Call the main function if this script is run as the main program\n",
    "\n",
    "# ref https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture\n",
    "x86_reg_re = (\"rip,?|rax,?|rbx,?|rcx,?|rdx,?|rsp,?|rbp,?|rsi,?|rdi,?|eax,?|ecx,?|edx,?|ebx,?|\"\n",
    "              \"esp,?|ebp,?|esi,?|edi,?|ax,?|cx,?|dx,?|bx,?|sp,?|bp,?|di,?|si,?|\"\n",
    "              \"ah,?|al,?|ch,?|cl,?|dh,?|dl,?|bh,?|bl,?|spl,?|bpl,?|sil,?|dil,?|st,?|\")\n",
    "\n",
    "# ref https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have\n",
    "bounds_regi = set(\n",
    "    ['bnd0', 'bnd0,', 'bnd1', 'bnd1,', 'bnd2', 'bnd2,', 'bnd3', 'bnd3,', 'bndcfg', 'bndcfg,', 'bndcfu', 'bndcfu,',\n",
    "     'bndstatus', 'bndstatus,'])\n",
    "debug_regi = set(['dr' + str(i) for i in range(8)] + ['dr' + str(i) + ',' for i in range(8)])\n",
    "control_regi = set(['cr' + str(i) for i in range(16)] + ['cr,' + str(i) for i in range(16)])\n",
    "stack_regi = set(['st(' + str(i) + ')' for i in range(8)] + ['st(' + str(i) + '),' for i in range(8)])\n",
    "sse_regi = set(['xmm' + str(i) for i in range(32)] + ['xmm' + str(i) + ',' for i in range(32)])\n",
    "avx_regi = set(['zmm' + str(i) for i in range(32)] + ['zmm' + str(i) + ',' for i in range(32)])\n",
    "av2_regi = set(['ymm' + str(i) for i in range(32)] + ['ymm' + str(i) + ',' for i in range(32)])\n",
    "gen_regi = set(['r' + str(i) for i in range(8, 16)] + ['r' + str(i) + ',' for i in range(8, 16)])\n",
    "# https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/x64-architecture\n",
    "gen2_regi = set(['r' + str(i) + 'b' for i in range(8, 16)] + ['r' + str(i) + 'b,' for i in range(8, 16)])\n",
    "gen3_regi = set(['r' + str(i) + 'd' for i in range(8, 16)] + ['r' + str(i) + 'd,' for i in range(8, 16)])\n",
    "gen4_regi = set(['r' + str(i) + 'w' for i in range(8, 16)] + ['r' + str(i) + 'w,' for i in range(8, 16)])\n",
    "x86_regi_set = set()\n",
    "x86_regi_set = set.union(bounds_regi, debug_regi, control_regi, stack_regi, sse_regi, avx_regi, av2_regi, gen_regi,\n",
    "                         gen2_regi, gen3_regi, gen4_regi)\n",
    "\n",
    "missed_opcodes = set(\n",
    "    ['cmpxchg', 'cmpxchg,', 'xadd', 'xadd,', 'movsq', 'movsq,', 'stosq', 'stosq,', 'scasb', 'scasb,', 'stosd', 'stosd,',\n",
    "     'cmpsb', 'cmpsb,', 'sub', 'sub,'])\n",
    "\n",
    "HOME = expanduser(\"~\")\n",
    "architecture = 'x86'\n",
    "folder_names = ['coreutils', 'diffutils', 'findutils', 'libgcrypt', 'libgpg-error', 'openssl', 'cmake']\n",
    "\n",
    "# FILE TYPE\n",
    "gdl = True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "instruction_mapping = defaultdict(set)\n",
    "unique_instructions = set()\n",
    "unknown_opcodes = set()\n",
    "\n",
    "# UBUNTU\n",
    "input_path = '/path/to_RAW_x86_GDL_files/'\n",
    "output_path = '/path/to_temporary_logs/'\n",
    "output_path_GDL_files = '/path/to/preprocessed/x86/GDL_files'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# get all .txt file names\n",
    "file_names = os.listdir(input_path)\n",
    "\n",
    "function_names = {}\n",
    "for file in file_names:\n",
    "    input_file = input_path + '/' + file\n",
    "    output_file = output_path + '/' + file.split('.gdl')[0] + '_funcGNN_formatted.txt'\n",
    "    output_file_gdl = output_path_GDL_files + '/' + file  # .split('.gdl')[0] + '_funcGNN_formatted.txt'\n",
    "\n",
    "    if gdl:\n",
    "        try:\n",
    "            run_gdl_processing(input_file, output_file, output_file_gdl)\n",
    "        except OSError as exc:\n",
    "            if exc.errno == 36:\n",
    "                new_name = handle_filename_too_long(file)\n",
    "                new_file = output_path + '/' + new_name\n",
    "                new_file_gdl = output_path_GDL_files + '/' + new_name\n",
    "\n",
    "                run_gdl_processing(input_file, new_file, new_file_gdl)\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        try:\n",
    "            preprocessing(input_file, output_file)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "execution_time = time.time() - start_time\n",
    "print(\"--- {} seconds ---\".format(execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
